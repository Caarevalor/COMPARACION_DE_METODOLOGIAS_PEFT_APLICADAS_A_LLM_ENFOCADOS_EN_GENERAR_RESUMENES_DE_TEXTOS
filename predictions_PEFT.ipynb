{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "TOKENIZER_NAME = \"openai-community/gpt2-large\"\n",
    "use_peft = False\n",
    "torch_dtype=torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_peft:\n",
    "    MODEL_NAME = f\"./{TOKENIZER_NAME}-peft=True-fine-tuned-model\"\n",
    "else:\n",
    "    MODEL_NAME = f\"./{TOKENIZER_NAME}-peft=False-fine-tuned-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Formatting libraries\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "# Load jupyter_black settings\n",
    "jupyter_black.load(\n",
    "    lab=True,\n",
    "    line_length=170,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"knkarthick/dialogsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define tokenizer. We will use the tokenizer to count the number of tokens per instance\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, padding_side=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define prompt template\n",
    "prompt_template = \"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Conversation:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "### Summary:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# create prompt\n",
    "def create_prompt(data):\n",
    "    dialogue = data[\"dialogue\"]\n",
    "    summary = data[\"summary\"]\n",
    "    prompt = prompt_template.format(dialogue=dialogue, summary=summary)\n",
    "\n",
    "    n_tokens_output = len(tokenizer.encode(summary, add_special_tokens=False))\n",
    "    n_tokens_input = len(tokenizer.encode(prompt, add_special_tokens=False))\n",
    "\n",
    "    return {\"input\": prompt, \"output\": summary, \"n_tokens_input\": n_tokens_input, \"n_tokens_output\": n_tokens_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input', 'output', 'n_tokens_input', 'n_tokens_output'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input', 'output', 'n_tokens_input', 'n_tokens_output'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input', 'output', 'n_tokens_input', 'n_tokens_output'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(create_prompt)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597.4099999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 0.95 percentile of dialogue length in training set\n",
    "dataset[\"train\"].to_pandas().n_tokens_input.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 0.95 quantile of n_tokens_summary in train dataset`\n",
    "dataset[\"train\"].to_pandas().n_tokens_output.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_input</th>\n",
       "      <th>n_tokens_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12460.000000</td>\n",
       "      <td>12460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>231.361637</td>\n",
       "      <td>34.867014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>103.897943</td>\n",
       "      <td>15.124341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>278.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1448.000000</td>\n",
       "      <td>247.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_tokens_input  n_tokens_output\n",
       "count    12460.000000     12460.000000\n",
       "mean       231.361637        34.867014\n",
       "std        103.897943        15.124341\n",
       "min         74.000000         7.000000\n",
       "25%        167.000000        24.000000\n",
       "50%        212.000000        32.000000\n",
       "75%        278.000000        42.000000\n",
       "max       1448.000000       247.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].to_pandas().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter very long dialogs and summaries\n",
    "dataset = dataset.filter(lambda x: x[\"n_tokens_input\"] < 470 and x[\"n_tokens_output\"] < 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Conversation:\n",
      "\n",
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n",
      "\n",
      "### Summary:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"input\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"output\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tined model and prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import LLMInference\n",
    "from peft import AutoPeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens: \n",
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, add_special_tokens=False)\n",
    "\n",
    "# verify the existing special tokens\n",
    "print(f\"Special Tokens: \\n{tokenizer.special_tokens_map}\")\n",
    "\n",
    "# if no padding token set eos_token as padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "if use_peft:\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cuda\")\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cuda\", torch_dtype=torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union\n",
    "from transformers import GenerationConfig\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "import transformers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_inference = LLMInference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28d0317db3f4c9a9f849467cd88983a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BLEU scores\n",
      "Computing ROUGE scores\n"
     ]
    }
   ],
   "source": [
    "llm_inference.make_predictions_and_compute_metrics(\n",
    "    dataset=dataset[\"test\"],\n",
    "    batch_size=15,\n",
    "    source_max_len=470,\n",
    "    padding_side=\"left\",\n",
    "    max_new_tokens=70,\n",
    "    do_sample=True,\n",
    "    temperature=0.5,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.0,\n",
    "    # generation_config_kwargs={\"num_beams\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>1-gram precision</th>\n",
       "      <th>2-gram precision</th>\n",
       "      <th>3-gram precision</th>\n",
       "      <th>4-gram precision</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bleu_score  1-gram precision  2-gram precision  3-gram precision  \\\n",
       "0       0.283             0.576             0.355             0.231   \n",
       "\n",
       "   4-gram precision  rouge1  rouge2  rougeL  rougeLsum  \n",
       "0             0.136   0.479    0.23     0.4        0.4  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_inference.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(f\"./predictions_and_metric/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Conversation:\n",
      "\n",
      "#Person1#:  So is there any other area I should look at as well?\n",
      "#Person2#: Yes, I'd recommend West Derby. That will be closer to your office.\n",
      "#Person1#:  That sounds good.\n",
      "#Person2#:  Yes, and if you have children, it also has very good schools.\n",
      "#Person1#:  That's not my concern. I live on my own so I'm only looking for a cheap single room, something like a flat.\n",
      "#Person2#:  Umm, that may be a problem here in this area then, because there are mostly larger houses here. You'd probably be able to share one with other people who want to rent though.\n",
      "#Person1#:  No, I'm only interested in flats at the moment.\n",
      "#Person2#:  We actually have another office in South Derby, and the guy who works there is a really good friend of mine. His name is John Godfrey.\n",
      "#Person1#:  Could you tell me his telephone number?\n",
      "#Person2#:  It's 074263951.\n",
      "#Person1#:  Great. Is there a good time to call him? I'm here for a whole week until Sunday tenth.\n",
      "#Person2#:  I'm sure he'll be able to see you on Saturday.\n",
      "#Person1#:  That sounds fine. Thanks for your help.\n",
      "\n",
      "### Summary:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predictions.input[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# wants a cheap single room. #Person2# recommends calling John Godfrey and see him on Saturday.\n"
     ]
    }
   ],
   "source": [
    "print(predictions.output[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# wants a flat. #Person2# recommends West Derby and #Person1#'s willing to share a flat with other people. #Person2# recommends another office in South Derby and John's willing to see #Person1# on Saturday.\n"
     ]
    }
   ],
   "source": [
    "print(predictions.prediction[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
